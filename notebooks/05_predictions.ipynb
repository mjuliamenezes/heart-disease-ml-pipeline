{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20961a4c",
   "metadata": {},
   "source": [
    "## 05 - Otimiza√ß√£o de Hiperpar√¢metros e Predi√ß√µes Finais\n",
    "1. Otimiza√ß√£o de hiperpar√¢metros (Grid Search)\n",
    "2. Treinamento do modelo otimizado\n",
    "3. Predi√ß√µes no conjunto de valida√ß√£o\n",
    "4. Compara√ß√£o com modelos base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dd24f2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a57bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/work')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from src import S3Client, ModelTrainer, ModelEvaluator, MLFlowClient, DatabaseClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b453dfa",
   "metadata": {},
   "source": [
    "# Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e34b07",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "s3 = S3Client()\n",
    "\n",
    "X_train = s3.read_csv('processed/X_train_scaled.csv')\n",
    "y_train = s3.read_csv('processed/y_train.csv')['target']\n",
    "X_test = s3.read_csv('processed/X_test_scaled.csv')\n",
    "y_test = s3.read_csv('processed/y_test.csv')['target']\n",
    "X_val = s3.read_csv('processed/X_val_scaled.csv')\n",
    "y_val = s3.read_csv('processed/y_val.csv')['target']\n",
    "\n",
    "print(f\"üìä Train: {X_train.shape}\")\n",
    "print(f\"üìä Test: {X_test.shape}\")\n",
    "print(f\"üìä Validation: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec8bb63",
   "metadata": {},
   "source": [
    "# Inicializa√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00234780",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer = ModelTrainer()\n",
    "evaluator = ModelEvaluator()\n",
    "mlflow_client = MLFlowClient(experiment_name=\"heart-disease-hyperparameter-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb1d1b",
   "metadata": {},
   "source": [
    "## Parte 1: Otimiza√ß√£o de Hiperpar√¢metros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6ed12",
   "metadata": {},
   "source": [
    "### Random Forest - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833fcf68",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"üîÑ Otimizando Random Forest...\")\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Modelo base\n",
    "rf_base = trainer.get_model('random_forest')\n",
    "\n",
    "# Grid Search\n",
    "print(f\"üìä Testando {np.prod([len(v) for v in rf_param_grid.values()])} combina√ß√µes...\")\n",
    "print(f\"‚è±Ô∏è  Isso pode levar alguns minutos...\\n\")\n",
    "\n",
    "rf_tuned, rf_best_params = trainer.hyperparameter_tuning(\n",
    "    model=rf_base,\n",
    "    param_grid=rf_param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(f\"\\nüèÜ Melhores hiperpar√¢metros Random Forest:\")\n",
    "for param, value in rf_best_params.items():\n",
    "    print(f\"   {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037011a1",
   "metadata": {},
   "source": [
    "### Logistic Regression - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbad541",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ Otimizando Logistic Regression...\")\n",
    "\n",
    "lr_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "lr_base = trainer.get_model('logistic_regression')\n",
    "\n",
    "print(f\"üìä Testando {np.prod([len(v) for v in lr_param_grid.values()])} combina√ß√µes...\")\n",
    "\n",
    "lr_tuned, lr_best_params = trainer.hyperparameter_tuning(\n",
    "    model=lr_base,\n",
    "    param_grid=lr_param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(f\"\\nüèÜ Melhores hiperpar√¢metros Logistic Regression:\")\n",
    "for param, value in lr_best_params.items():\n",
    "    print(f\"   {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d2c72",
   "metadata": {},
   "source": [
    "### SVM - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca9bfd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ Otimizando SVM...\")\n",
    "\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'poly']\n",
    "}\n",
    "\n",
    "svm_base = trainer.get_model('svm')\n",
    "\n",
    "print(f\"üìä Testando {np.prod([len(v) for v in svm_param_grid.values()])} combina√ß√µes...\")\n",
    "print(\"‚ö†Ô∏è  SVM pode demorar mais...\")\n",
    "\n",
    "svm_tuned, svm_best_params = trainer.hyperparameter_tuning(\n",
    "    model=svm_base,\n",
    "    param_grid=svm_param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(f\"\\nüèÜ Melhores hiperpar√¢metros SVM:\")\n",
    "for param, value in svm_best_params.items():\n",
    "    print(f\"   {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030a22d",
   "metadata": {},
   "source": [
    "## Parte 2: Avaliar Modelos Otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34002b1c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tuned_models = {\n",
    "    'random_forest_optimized': rf_tuned,\n",
    "    'logistic_regression_optimized': lr_tuned,\n",
    "    'svm_optimized': svm_tuned\n",
    "}\n",
    "\n",
    "results_tuned = []\n",
    "\n",
    "for name, model in tuned_models.items():\n",
    "    print(f\"\\nüîÑ Avaliando: {name}\")\n",
    "    \n",
    "    # Predi√ß√µes\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Avaliar\n",
    "    metrics = evaluator.evaluate_model(y_test, y_pred, y_pred_proba, model_name=name)\n",
    "    results_tuned.append(metrics)\n",
    "    \n",
    "    # Registrar no MLFlow\n",
    "    run = mlflow_client.start_run(run_name=f\"tuned_{name}\")\n",
    "    \n",
    "    mlflow_client.log_params(model.get_params())\n",
    "    mlflow_client.log_metrics({\n",
    "        'test_accuracy': metrics['accuracy'],\n",
    "        'test_precision': metrics['precision'],\n",
    "        'test_recall': metrics['recall'],\n",
    "        'test_f1': metrics['f1_score']\n",
    "    })\n",
    "    mlflow_client.log_model(model, artifact_path=\"model\", registered_model_name=name)\n",
    "    mlflow_client.end_run()\n",
    "\n",
    "print(\"\\n‚úÖ Modelos otimizados avaliados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f080c8",
   "metadata": {},
   "source": [
    "### Compara√ß√£o: Base vs Otimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545ab0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_models_names = ['random_forest', 'logistic_regression', 'svm']\n",
    "results_base = []\n",
    "\n",
    "for name in base_models_names:\n",
    "    try:\n",
    "        # Carregar modelo base do MLFlow\n",
    "        model_uri = f\"models:/{name}/latest\"\n",
    "        model = mlflow_client.load_model(model_uri)\n",
    "        \n",
    "        # Predi√ß√µes\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Avaliar\n",
    "        metrics = evaluator.evaluate_model(y_test, y_pred, y_pred_proba, model_name=name)\n",
    "        results_base.append(metrics)\n",
    "    except:\n",
    "        print(f\"‚ö†Ô∏è  Modelo base {name} n√£o encontrado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207469ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "comparison_data = []\n",
    "\n",
    "for base, tuned in zip(results_base, results_tuned):\n",
    "    comparison_data.append({\n",
    "        'Model': base['model_name'].replace('_', ' ').title(),\n",
    "        'Base Accuracy': base['accuracy'],\n",
    "        'Tuned Accuracy': tuned['accuracy'],\n",
    "        'Improvement': tuned['accuracy'] - base['accuracy'],\n",
    "        'Improvement %': (tuned['accuracy'] - base['accuracy']) / base['accuracy'] * 100\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\nüìä Compara√ß√£o Base vs Otimizado:\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a3d53",
   "metadata": {},
   "source": [
    "### Visualiza√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363b0a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, comparison_df['Base Accuracy'], width, \n",
    "               label='Base', color='#3498db', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, comparison_df['Tuned Accuracy'], width,\n",
    "               label='Otimizado', color='#e74c3c', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Modelo')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Compara√ß√£o: Modelos Base vs Otimizados')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df['Model'])\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237ea5b",
   "metadata": {},
   "source": [
    "## Parte 3: Predi√ß√µes no Conjunto de Valida√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969e9fbc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "best_tuned = max(results_tuned, key=lambda x: x['accuracy'])\n",
    "best_model_name = best_tuned['model_name']\n",
    "best_accuracy = best_tuned['accuracy']\n",
    "\n",
    "print(f\"\\nüèÜ Melhor modelo otimizado: {best_model_name}\")\n",
    "print(f\"   Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Carregar melhor modelo\n",
    "best_model = tuned_models[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7736d784",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ Realizando predi√ß√µes no conjunto de valida√ß√£o...\")\n",
    "\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "y_val_pred_proba = best_model.predict_proba(X_val) if hasattr(best_model, 'predict_proba') else None\n",
    "\n",
    "# Avaliar\n",
    "val_metrics = evaluator.evaluate_model(\n",
    "    y_val, \n",
    "    y_val_pred, \n",
    "    y_val_pred_proba,\n",
    "    model_name=f\"{best_model_name}_validation\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Resultados no Conjunto de Valida√ß√£o:\")\n",
    "print(f\"   Accuracy:  {val_metrics['accuracy']:.4f}\")\n",
    "print(f\"   Precision: {val_metrics['precision']:.4f}\")\n",
    "print(f\"   Recall:    {val_metrics['recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {val_metrics['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34d7e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cm_val = evaluator.get_confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=['Saud√°vel', 'Doen√ßa'],\n",
    "           yticklabels=['Saud√°vel', 'Doen√ßa'])\n",
    "plt.title(f'Matriz de Confus√£o - Valida√ß√£o\\n{best_model_name}')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predito')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c50f8",
   "metadata": {},
   "source": [
    "# Salvar predi√ß√µes e Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac194f9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'patient_id': range(len(y_val)),\n",
    "    'true_label': y_val.values,\n",
    "    'predicted_label': y_val_pred,\n",
    "    'probability_disease': y_val_pred_proba[:, 1] if y_val_pred_proba is not None else y_val_pred,\n",
    "    'correct': y_val.values == y_val_pred\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Primeiras predi√ß√µes:\")\n",
    "display(predictions_df.head(10))\n",
    "\n",
    "# Estat√≠sticas\n",
    "correct_count = predictions_df['correct'].sum()\n",
    "total_count = len(predictions_df)\n",
    "\n",
    "print(f\"\\n‚úÖ Predi√ß√µes corretas: {correct_count}/{total_count} ({correct_count/total_count*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082bdc11",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "s3.write_csv(predictions_df, 'predictions/validation_predictions.csv')\n",
    "print(\"\\n‚úÖ Predi√ß√µes salvas no MinIO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb30945",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Registrar como modelo de produ√ß√£o\n",
    "model_version = mlflow_client.register_model(\n",
    "    run_id=mlflow_client.client.search_runs(\n",
    "        experiment_ids=[mlflow_client.experiment_id],\n",
    "        filter_string=f\"tags.mlflow.runName = 'tuned_{best_model_name}'\",\n",
    "        max_results=1\n",
    "    )[0].info.run_id,\n",
    "    model_name=\"production_model\",\n",
    "    artifact_path=\"model\"\n",
    ")\n",
    "\n",
    "# Transicionar para produ√ß√£o\n",
    "mlflow_client.transition_model_stage(\n",
    "    model_name=\"production_model\",\n",
    "    version=model_version,\n",
    "    stage=\"Production\"\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo de produ√ß√£o registrado: production_model v{model_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b075b",
   "metadata": {},
   "source": [
    "# Resumo Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d058d0",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä RESUMO FINAL DO PROJETO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüéØ MODELOS BASE (Artigo):\")\n",
    "for result in results_base:\n",
    "    print(f\"   {result['model_name']}: {result['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nüöÄ MODELOS OTIMIZADOS:\")\n",
    "for result in results_tuned:\n",
    "    print(f\"   {result['model_name']}: {result['accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nüèÜ MELHOR MODELO: {best_model_name}\")\n",
    "print(f\"   Test Accuracy:       {best_accuracy:.4f}\")\n",
    "print(f\"   Validation Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà MELHORIA M√âDIA: {comparison_df['Improvement %'].mean():.2f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ PROJETO CONCLU√çDO!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
