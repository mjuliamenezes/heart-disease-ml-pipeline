# ü´Ä Heart Disease ML Pipeline

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)
[![Docker](https://img.shields.io/badge/docker-ready-brightgreen.svg)](https://www.docker.com/)

## üë• Equipe de Desenvolvimento

- **Andr√© Luiz G. C. da Fonseca** - algcf@cesar.school
- **Gabriel C. G. P. Farias** - gcgpf@cesar.school
- **Jo√£o Vitor M. Fittipaldi** - jvmf@cesar.school
- **Maria J√∫lia O. T. Menezes** - mjotm@cesar.school
- **Maria Lu√≠sa C. Lima** - mlcl@cesar.school

---

## üìÑ Abstract

This work presents the development of a complete architecture for predicting ischemic cardiovascular diseases, built from the reproduction and expansion of the study *"Enhancing Prognosis Accuracy for Ischemic Cardiovascular Disease Using K Nearest Neighbor Algorithm: A Robust Approach"*. The solution was structured as a fully integrated and containerized data pipeline, involving an ingestion API developed with FastAPI, distributed storage using MinIO, a modeling environment in JupyterLab, and experiment tracking with MLFlow. Several algorithms were analyzed, including KNN, Random Forest, Gradient Boosting, among others, with the objective of comparing performance and validating the original methodology. The experimental analysis demonstrated that the optimized Gradient Boosting model offered the best balance between accuracy, stability, and predictive capability, standing out as the most suitable approach for the clinical scenario addressed.

**Artigo Original:** [IEEE Xplore](https://ieeexplore.ieee.org/document/10239171)

---

## üèóÔ∏è Arquitetura do Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    HEART DISEASE ML PIPELINE                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Raw Data   ‚îÇ
    ‚îÇ  (heart.csv) ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   FastAPI    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ HTTP Requests
    ‚îÇ  (Ingest√£o)  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         MinIO (S3-like)          ‚îÇ
    ‚îÇ  ‚Ä¢ Raw data                      ‚îÇ
    ‚îÇ  ‚Ä¢ Processed data                ‚îÇ
    ‚îÇ  ‚Ä¢ Trained models (.pkl)         ‚îÇ
    ‚îÇ  ‚Ä¢ Model metadata                ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ                  ‚îÇ
           ‚ñº                  ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ PostgreSQL  ‚îÇ    ‚îÇ  JupyterLab ‚îÇ
    ‚îÇ (Metadados) ‚îÇ    ‚îÇ (Notebooks) ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                  ‚îÇ
           ‚îÇ                  ‚îÇ ‚Ä¢ 01_exploratory_analysis.ipynb
           ‚îÇ                  ‚îÇ ‚Ä¢ 02_preprocessing.ipynb
           ‚îÇ                  ‚îÇ ‚Ä¢ 03_model_training.ipynb
           ‚îÇ                  ‚îÇ ‚Ä¢ 04_model_evaluation.ipynb
           ‚îÇ                  ‚îÇ ‚Ä¢ 05_predictions.ipynb
           ‚îÇ                  ‚îÇ
           ‚îÇ                  ‚ñº
           ‚îÇ           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ           ‚îÇ   MLflow    ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ (Tracking)  ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚îÇ Model Registry
                              ‚îÇ Experiment Logs
                              ‚îÇ
                              ‚ñº
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ  Production ‚îÇ
                       ‚îÇ    Model    ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ    Streaming    ‚îÇ
                       ‚îÇ   Simulator     ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ  ThingsBoard    ‚îÇ
                       ‚îÇ   (Dashboard)   ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ In√≠cio R√°pido

### üìã Pr√©-requisitos

- **Docker** 20.10+ e **Docker Compose** 2.0+
- **Python** 3.11+
- **Git**
- 8GB RAM m√≠nimo
- 15GB espa√ßo em disco

### üêß Instala√ß√£o - Linux

#### 1. Clone o Reposit√≥rio

```bash
git clone https://github.com/seu-usuario/heart-disease-ml-pipeline.git
cd heart-disease-ml-pipeline
```

#### 2. Configure Vari√°veis de Ambiente

```bash
# Criar arquivo .env na raiz do projeto
Solicite as vari√°veis de ambiente
```

#### 3. Build e Inicializa√ß√£o dos Containers

```bash
# Build das imagens
docker compose build

# Subir todos os servi√ßos
docker compose up -d

# Verificar status (aguardar todos ficarem "healthy")
docker compose ps
```

#### 4. Testar Pipeline Base

```bash
# Dar permiss√£o de execu√ß√£o
chmod +x scripts/test_pipeline.sh

# Executar testes
./scripts/test_pipeline.sh
```

#### 5. Carregar Dados Iniciais no MinIO

```bash
# Dividir dados em treino/teste/valida√ß√£o
python3 scripts/split_data.py

# Upload para MinIO
python3 scripts/upload_to_minio.py
```

#### 6. Executar Notebooks de Treinamento

Acessar JupyterLab em http://localhost:8888 e executar na ordem:

1. `notebooks/01_data_ingestion.ipynb` - Ingest√£o e valida√ß√£o dos dados
2. `notebooks/02_eda.ipynb` - An√°lise explorat√≥ria
3. `notebooks/03_model_training.ipynb` - Treinamento dos modelos base
4. `notebooks/04_model_evaluation.ipynb` - Avalia√ß√£o e compara√ß√£o
5. `notebooks/05_hyperparameter_tuning.ipynb` - Otimiza√ß√£o e modelo de produ√ß√£o

#### 7. Testar API de Predi√ß√£o

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "age": 54,
    "sex": 1,
    "chest_pain_type": 3,
    "resting_bp": 150,
    "cholesterol": 195,
    "fasting_bs": 0,
    "resting_ecg": 0,
    "max_hr": 122,
    "exercise_angina": 0,
    "oldpeak": 0.0,
    "st_slope": 1
  }'
```

#### 8. Configurar Tabela de Predi√ß√µes no PostgreSQL

```bash
# Copiar script SQL para o container
docker cp scripts/add_predictions_table.sql heart-postgres:/tmp/

# Executar script
docker compose exec postgres psql -U postgres -d mlflow_db -f /tmp/add_predictions_table.sql

# Verificar cria√ß√£o das tabelas
docker compose exec postgres psql -U postgres -d mlflow_db -c "\dt heart_disease.*"
```

#### 9. Subir Streaming Simulator

```bash
# Build do container de streaming
docker compose build streaming

# Executar streaming (modo daemon)
docker compose --profile streaming up streaming
```

#### 10. Testar Streaming com Visualiza√ß√£o em Tempo Real

```bash
# Processar 20 amostras com delay de 0.5s
docker compose run --rm streaming python stream_simulator.py \
  --delay 0.5 \
  --max-samples 20 \
  --no-api

# Acessar dashboard ThingsBoard: http://localhost:8080
```

---

### ü™ü Instala√ß√£o - Windows

#### 1. Instalar Pr√©-requisitos

- Instalar [Docker Desktop for Windows](https://www.docker.com/products/docker-desktop/)
- Instalar [Python 3.11+](https://www.python.org/downloads/)
- Instalar [Git for Windows](https://git-scm.com/download/win)

#### 2. Clone o Reposit√≥rio

```powershell
git clone https://github.com/seu-usuario/heart-disease-ml-pipeline.git
cd heart-disease-ml-pipeline
```

#### 3. Configure Vari√°veis de Ambiente

```
# Criar arquivo .env na raiz do projeto
Solicite as vari√°veis de ambiente
```

#### 4. Build e Inicializa√ß√£o

```powershell
# Build
docker compose build

# Subir servi√ßos
docker compose up -d

# Verificar status
docker compose ps
```

#### 5. Carregar Dados

```powershell
python scripts\split_data.py
python scripts\upload_to_minio.py
```

#### 6-10. Seguir os mesmos passos do Linux

Os comandos `docker compose`, `curl` e acesso aos notebooks s√£o id√™nticos no Windows.

---

## üîó Acesso aos Servi√ßos

| Servi√ßo | URL | Credenciais |
|---------|-----|-------------|
| **JupyterLab** | http://localhost:8888 | Sem senha |
| **MLflow** | http://localhost:5000 | - |
| **MinIO Console** | http://localhost:9001 | minioadmin / minioadmin123 |
| **FastAPI (Swagger)** | http://localhost:8000/docs | - |
| **ThingsBoard** | http://localhost:8080 | tenant@thingsboard.org / tenant |
| **PostgreSQL** | localhost:5432 | postgres / postgres |

---

## üìä Dataset

**Heart Disease Dataset (Comprehensive)** - Kaggle

- **Fonte:** https://www.kaggle.com/datasets/sid321axn/heart-statlog-cleveland-hungary-final
- **Registros:** 1190 pacientes
- **Features:** 11 atributos cl√≠nicos
- **Target:** Presen√ßa de doen√ßa card√≠aca (0=Saud√°vel, 1=Doen√ßa)

### Atributos

| Atributo | Tipo | Descri√ß√£o |
|----------|------|-----------|
| age | int | Idade do paciente |
| sex | int | Sexo (1=M, 0=F) |
| chest pain type | int | Tipo de dor no peito (0-3) |
| resting bp s | int | Press√£o arterial em repouso (mm Hg) |
| cholesterol | int | Colesterol s√©rico (mg/dl) |
| fasting blood sugar | int | Glicemia em jejum > 120 mg/dl (1=sim, 0=n√£o) |
| resting ecg | int | Resultado ECG em repouso (0-2) |
| max heart rate | int | Frequ√™ncia card√≠aca m√°xima alcan√ßada |
| exercise angina | int | Angina induzida por exerc√≠cio (1=sim, 0=n√£o) |
| oldpeak | float | Depress√£o ST induzida por exerc√≠cio |
| ST slope | int | Inclina√ß√£o do segmento ST (0-2) |

---

## ü§ñ Modelos Implementados

### Modelos Base (Reprodu√ß√£o do Artigo)

1. **K-Nearest Neighbors (KNN)**
2. **Random Forest**
3. **Logistic Regression**
4. **Support Vector Machine (SVM)**
5. **Naive Bayes**
6. **Decision Tree**

### Modelos de Melhoria

7. **Gradient Boosting** ‚≠ê
8. **Random Forest Tuned**

### Modelos Otimizados (Grid Search)

9. **Random Forest Optimized**
10. **Logistic Regression Optimized**
11. **SVM Optimized**
12. **Gradient Boosting Optimized** üèÜ
13. **Random Forest Tuned v2**

---

## üìà Resultados

### Performance dos Modelos (Top 5)

| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| **Gradient Boosting Optimized** üèÜ | **92.51%** | 0.9250 | 0.9251 | 0.9250 | 0.9698 |
| Random Forest Tuned v2 | 91.19% | 0.9123 | 0.9119 | 0.9121 | 0.9654 |
| Random Forest Optimized | 90.74% | 0.9078 | 0.9074 | 0.9076 | 0.9621 |
| Gradient Boosting | 89.87% | 0.8991 | 0.8987 | 0.8989 | 0.9587 |
| Random Forest | 89.43% | 0.8947 | 0.8943 | 0.8945 | 0.9543 |

### Modelo de Produ√ß√£o

**Gradient Boosting Optimized**
- Test Accuracy: **91.38%**
- Validation Accuracy: **92.51%**
- Armazenado em: `models/production_model/`

### Compara√ß√£o com Artigo Original

| M√©trica | Artigo Original (KNN) | Nossa Implementa√ß√£o (GB) | Melhoria |
|---------|----------------------|--------------------------|----------|
| Accuracy | 91.80% | 92.51% | **+0.71%** |

---

## üéØ Dashboard ThingsBoard

O dashboard fornece monitoramento em tempo real das predi√ß√µes:

### Widgets Implementados

- **Gauge de Acur√°cia** - Visualiza√ß√£o circular da performance atual
- **Timeline de Predi√ß√µes** - Gr√°fico de linha comparando predi√ß√µes vs realidade
- **Gr√°fico de Probabilidades** - Distribui√ß√£o das probabilidades ao longo do tempo
- **Cards de M√©tricas** - Total de predi√ß√µes, corretas e acur√°cia
- **Tabela de √öltimas Predi√ß√µes** - Hist√≥rico detalhado com filtros

### Configura√ß√£o

1. Acesse: http://localhost:8080
2. Login com `tenant@thingsboard.org` / `tenant`
3. V√° em **Dashboards** ‚Üí **Heart Disease Predictions**
4. Execute o streaming para ver dados em tempo real

---

## üìÅ Estrutura do Projeto

```
heart-disease-ml-pipeline/
‚îú‚îÄ‚îÄ api/                          # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Endpoints principais
‚îÇ   ‚îú‚îÄ‚îÄ models.py                 # Modelos Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # Configura√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ notebooks/                    # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploratory_analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_model_training.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_model_evaluation.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 05_predictions.ipynb
‚îú‚îÄ‚îÄ src/                          # C√≥digo fonte Python
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ s3_utils.py               # Cliente MinIO/S3
‚îÇ   ‚îú‚îÄ‚îÄ db_utils.py               # Cliente PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ mlflow_utils.py           # Cliente MLflow
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py          # Pr√©-processamento
‚îÇ   ‚îú‚îÄ‚îÄ model_training.py          # Treinamento
‚îÇ   ‚îî‚îÄ‚îÄ model_evaluation.py        # Avalia√ß√£o
‚îú‚îÄ‚îÄ streaming/                    # Simulador de streaming
‚îÇ   ‚îú‚îÄ‚îÄ stream_simulator.py
‚îÇ   ‚îú‚îÄ‚îÄ thingsboard_client.py
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ scripts/                      # Scripts auxiliares
‚îÇ   ‚îú‚îÄ‚îÄ test_pipeline.sh
‚îÇ   ‚îú‚îÄ‚îÄ split_data.py
‚îÇ   ‚îú‚îÄ‚îÄ upload_to_minio.py
‚îÇ   ‚îî‚îÄ‚îÄ add_predictions_table.sql
‚îú‚îÄ‚îÄ data/                         # Dados locais
‚îÇ   ‚îî‚îÄ‚îÄ raw/
‚îÇ       ‚îî‚îÄ‚îÄ heart.csv
‚îú‚îÄ‚îÄ database/                     # Scripts SQL
‚îÇ   ‚îî‚îÄ‚îÄ init.sql
‚îú‚îÄ‚îÄ thingsboard/                  # Configura√ß√µes ThingsBoard
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îî‚îÄ‚îÄ dashboard_config.json
‚îú‚îÄ‚îÄ mlflow/                       # MLflow setup
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml            # Orquestra√ß√£o de containers             
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

## üîß Comandos √öteis

### Gerenciamento de Containers

```bash
# Ver logs de um servi√ßo
docker compose logs -f [service_name]

# Restart de servi√ßo espec√≠fico
docker compose restart [service_name]

# Parar todos os servi√ßos
docker compose down

# Limpar volumes (‚ö†Ô∏è apaga dados)
docker compose down -v

# Rebuild sem cache
docker compose build --no-cache [service_name]

# Ver uso de recursos
docker stats
```

### Streaming

```bash
# Streaming com configura√ß√µes customizadas
docker compose run --rm streaming python stream_simulator.py \
  --delay 0.5 \
  --max-samples 100 \
  --no-api

# Ver todas as op√ß√µes
docker compose run --rm streaming python stream_simulator.py --help
```

### Banco de Dados

```bash
# Acessar PostgreSQL
docker compose exec postgres psql -U postgres -d mlflow_db

# Ver tabelas
docker compose exec postgres psql -U postgres -d mlflow_db -c "\dt heart_disease.*"

# Query de predi√ß√µes
docker compose exec postgres psql -U postgres -d mlflow_db -c \
  "SELECT * FROM heart_disease.predictions ORDER BY created_at DESC LIMIT 10;"

# Backup do banco
docker compose exec postgres pg_dump -U postgres mlflow_db > backup.sql
```

### MinIO

```bash
# Listar arquivos
docker compose exec minio mc ls myminio/ml-bucket-heart/

# Copiar arquivo para local
docker compose exec minio mc cp myminio/ml-bucket-heart/models/production_model_metadata.csv /tmp/
```

---


## üêõ Troubleshooting

### API n√£o inicia

```bash
docker compose logs api
docker compose restart api
```

### ThingsBoard n√£o recebe dados

```bash
# Verificar se ThingsBoard est√° rodando
docker compose ps thingsboard

# Ver logs
docker compose logs thingsboard | tail -50

# Verificar token
echo $THINGSBOARD_TOKEN
```

### Incompatibilidade de vers√£o scikit-learn

```bash
# Verificar vers√£o no Jupyter
docker compose exec jupyter pip show scikit-learn

# Verificar vers√£o no streaming
docker compose exec streaming pip show scikit-learn

# Devem ser id√™nticas (1.7.2)
```

### Modelo n√£o carrega

```bash
# Verificar arquivos no MinIO
docker compose exec minio mc ls myminio/ml-bucket-heart/models/

# Testar carregamento direto
docker compose run --rm streaming python -c "
from src.s3_utils import S3Client
s3 = S3Client()
model = s3.load_model('models/production_model/20251201_231253/model.pkl')
print('OK' if model else 'ERRO')
"
```

---

## üìö Refer√™ncias

1. **Artigo Original:**  
   Enhancing Prognosis Accuracy for Ischemic Cardiovascular Disease Using K Nearest Neighbor Algorithm: A Robust Approach  
   IEEE Xplore: https://ieeexplore.ieee.org/document/10239171

2. **Dataset:**  
   Kaggle - Heart Disease Dataset (Comprehensive) 
   https://www.kaggle.com/datasets/sid321axn/heart-statlog-cleveland-hungary-final

3. **Tecnologias:**
   - [Docker](https://www.docker.com/)
   - [FastAPI](https://fastapi.tiangolo.com/)
   - [MLflow](https://mlflow.org/)
   - [MinIO](https://min.io/)
   - [ThingsBoard](https://thingsboard.io/)
   - [scikit-learn](https://scikit-learn.org/)

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

## üìß Contato

Para d√∫vidas ou sugest√µes, entre em contato com a equipe atrav√©s dos emails listados no in√≠cio deste documento.
